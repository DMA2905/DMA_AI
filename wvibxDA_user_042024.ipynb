{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoiTn/lEdgWKPHz4roQzAy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DMA2905/DMA_AI/blob/main/wvibxDA_user_042024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Schritt 1 - Vorbereitungen\n",
        "Zuerst gilt es, die Softwarebibliotheken zu importieren, die wir benötigen, um unser Forecast-Modell zu bauen. Wir arbeiten hier mit PyTorch. Es macht Sinn, die importierte Version von PyTorch überprüfen, da es je nach Versionierung Unterschiede geben kann.\n",
        "\n",
        " Die jeweils aktuellste Version können Sie jederzeit auf PyTorch.org überprüfen:\n",
        "\n",
        "https://pytorch.org/"
      ],
      "metadata": {
        "id": "uuVHFtic_2QC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import der PyTorch Bibliotheken\n",
        "import [AAAA]\n",
        "from torch import [AAAA]\n",
        "\n",
        "# Import visualization Bib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Überprüfen der PyTorch Versionierung\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "mJmOSLzPAhqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Schritt 2 - Datenbasis importieren und aufbereiten\n",
        "Unsere Datenlage basiert auf Schokiverkäufen im vergangen Jahr. Die zur Verfügung stehenden Informationen bestehen aus:\n",
        "\n",
        "\n",
        "*   Datum\n",
        "*   Temperatur\n",
        "*   Menge\n",
        "*   Sonnenschein\n",
        "*   Sondereffekte\n",
        "*   Wochenende\n",
        "*   Sonderoeffnungszeiten\n",
        "\n",
        "\n",
        "Unser Forecast-Modell soll Mengen basierend auf der Temperaturveränderung vorhersagen.\n",
        "\n"
      ],
      "metadata": {
        "id": "rzXnepnjBAIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check to see if we have a GPU to use for training\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('A {} device was detected.'.format(device))\n",
        "\n",
        "# Print the name of the cuda device, if detected\n",
        "if device=='cuda':\n",
        "    print (torch.cuda.get_dwevice_name (device=device))"
      ],
      "metadata": {
        "id": "ixOXUihimkwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wir verwenden die pandas Bib um div. statistische Berechnungen druchzuführen\n",
        "# Download Datenbasis\n",
        "import [AAAA] as pd\n",
        "url = 'https://raw.githubusercontent.com/DMA2905/DMA_AI/main/dummy_data_test.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Anzeigen der ersten 10 Zeilen\n",
        "df.head(AAAA)\n"
      ],
      "metadata": {
        "id": "QjywSLGUDD-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kurzes überprüfen der Struktur unseres Files\n",
        "df.[AAAAA]"
      ],
      "metadata": {
        "id": "CoEdF06kUHZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CZuweisen von Input und Output Daten zur Erstellung unseres Forecasts\n",
        "\n",
        "Wie oben gesehen, besteht die Datenbasis aus 7 Spalten:  \n",
        "\n",
        "<pre> Datum, Menge, Temparatur, Sonnenschein, Sondereffekt, Wochenende, Sonderöffnungszeit</pre>\n",
        "\n",
        "Idealer Weise wird ein neuronales Netwerk auf basis von einer Range -1 bis 1 trainiert. Unsere Spalte 'Menge' hingegen enthält eine breite Ausprägung von Merkmalen. Mittels Standardisierung werden wir daher unsere Daten in ein Brauchbares Format umwandeln."
      ],
      "metadata": {
        "id": "x8QloDK-UTq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Berechnen des Mittels und der Standardabweichung\n",
        "# Standardisieren der Menge numMenge\n",
        "\n",
        "numMengeMean = df[\"Menge\"].mean()\n",
        "numMengeStd = df[\"Menge\"].[AAAAA]\n",
        "df['Menge'] = (df['Menge']-numMengeMean)/numMengeStd\n",
        "\n",
        "# Standardisieren der Temparatur numTemp\n",
        "numTempMean =[AAAAA]\n",
        "numTempStd = [AAAAA]]\n",
        "df['Temperatur'] = (df['Temperatur']-numTempMean)/numTempStd\n"
      ],
      "metadata": {
        "id": "53VW80nCU7wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "aF4DumUKVY_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Datum rauswerfen\n",
        "df.drop('Datum', axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "6xHpuaWzZmHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "cdHiy5yZZseK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Schritt 2 - Festlegen von Input und Output zu Trainingszwecken\n",
        "\n",
        "Da die Datenbasis soweit aufbereitet ist, können wir jetzt mit dem Festlegen der Variablen beginnen. Wir nehmen den Input (x) und den Output (y) um unser NN zu trainieren. Wir möchten, dass die Menge vorhergesagt wird. Basieren wird dies auf unserem Input: Datum und Temparatur."
      ],
      "metadata": {
        "id": "OVu4UjIcVhyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Erstellen unseres PyTorch tensors\n",
        "# Aufbereiten der Inputs und zuweisen zum tensor x (inputs)\n",
        "inputs = [AAAAA]\n",
        "x = torch.tensor(df[inputs].values, dtype=torch.float, device=device)\n",
        "\n",
        "# Aufbereiten der Outputs und zuweisen zum tensor y (outputs)\n",
        "outputs = [AAAAA]\n",
        "y = torch.tensor(df[outputs].values,dtype=torch.float, device = device)"
      ],
      "metadata": {
        "id": "aspU0eIhWPS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #kurzes Prüfen der Top-10 Inputs\n",
        "x[0:10]"
      ],
      "metadata": {
        "id": "floacARGakMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kurzes Prfüen der Top-10 Outputs\n",
        "y[0:10]"
      ],
      "metadata": {
        "id": "wAlIDlM7aqTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Schritt 3 - Aufbauen des Neuronalen Netwerks\n",
        "Im Folgenden werden Sie ein einfaches neuronales Netzwerk erstellen, das die oben genannten Eingaben (10) aufnimmt und einen einzelnen Wert als Ausgabe liefert. Dieses Netzwerk verfügt über einen einzigen sogenannten \"hidden layer\" mit 100 Einheiten. Das bedeutet, das eine Schicht von 100 Neuronen, zwischen der Eingabe- (Input) und der Ausgabe- (Output) Schicht liegen. Diese Schichten sind „versteckt“, weil ihre Eingaben und Ausgaben nicht direkt sichtbar sind, wenn man das neuronale Netzwerk als Ganzes betrachtet. Stattdessen erhalten sie Eingaben von der vorherigen Schicht (die die Eingabeschicht oder eine andere versteckte Schicht sein kann), führen Berechnungen durch und geben ihre Ergebnisse an die nächste Schicht weiter (die eine weitere versteckte Schicht oder die Ausgabeschicht sein kann)."
      ],
      "metadata": {
        "id": "EXYYlxnLa1nK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Festlegen des PyTorch NN\n",
        "# Inputs: 5\n",
        "# Hidden Units: 100\n",
        "# Hidden Layers: 1\n",
        "# Activation Function:  Relu\n",
        "# Ouputs: 1\n",
        "model = nn.Sequential(\n",
        "            nn.Linear([AAAA]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear([AAAAA])\n",
        "        )\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "q2PIQxUIbzLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Schritt 4 - Trainieren des Neuronalen Netzwerks\n",
        "\n",
        "In diesem Schritt unterziehen wir unser neuronales Netzwerk einem Trainingsprozess, indem wir ihm Eingabedaten und die entsprechenden Ausgabedaten zur Verfügung stellen. Während des Trainings wird die Schleife kontinuierlich die internen Gewichte des Netzwerks anpassen. Ziel ist es, die Genauigkeit des Netzwerks bei der Vorhersage von Ausgaben basierend auf den Eingaben mit jedem Durchlauf des Trainings zu verbessern."
      ],
      "metadata": {
        "id": "99PYljUhddMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Bewerte unser neuronales Netzwerk mit mittlerem quadratischen Fehler\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "# Trainiere unser Netzwerk mit einem einfachen SGD-Ansatz\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Trainiere unser Netzwerk 5 Mal unter Verwendung des gesamten Datensatzes\n",
        "for epoch in range(5):\n",
        "    totalLoss = 0\n",
        "    for i in range(len(x)):\n",
        "\n",
        "        # Einzelner Vorwärtsdurchgang\n",
        "        ypred = model(x[i])\n",
        "\n",
        "        # Bewerte, wie gut das Modell im Vergleich zu den tatsächlichen Werten vorhergesagt hat\n",
        "        loss = criterion(ypred, y[i])\n",
        "\n",
        "        # Verfolge, wie gut das Modell vorhergesagt hat\n",
        "        totalLoss+=loss.item()\n",
        "\n",
        "        # Aktualisiere das neuronale Netzwerk\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Gib unseren Verlust nach jedem Trainingsdurchgang aus\n",
        "    print(\"Gesamtverlust: \", totalLoss)\n"
      ],
      "metadata": {
        "id": "UBrUXR3rcdJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Schritt 5 - Analysieren der Treffergenauigkeit unserer Vorhersagen"
      ],
      "metadata": {
        "id": "BruYerpcdyzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vorhersage des NN vs. Ist Absätze\n",
        "@torch.no_grad()\n",
        "def graphPredictions(model, x, y , minValue, maxValue):\n",
        "\n",
        "    model.eval()                               # Set the model to inference mode\n",
        "\n",
        "    predictions=[]                             # Track predictions\n",
        "    actual=[]                                  # Track the actual labels\n",
        "\n",
        "    x.to(device)\n",
        "    y.to(device)\n",
        "    model.to(device)\n",
        "\n",
        "    for i in range(len(x)):\n",
        "\n",
        "        # Single forward pass\n",
        "        pred = model(x[i])\n",
        "\n",
        "        # Un-normalize our prediction\n",
        "        pred = pred*numMengeStd+numMengeMean\n",
        "        act = y[i]*numMengeStd+numMengeMean\n",
        "\n",
        "        # Forhersage Speichern\n",
        "        predictions.append(pred.tolist())\n",
        "        actual.append(act.item())\n",
        "\n",
        "    # Vorhersage vs Ist\n",
        "    plt.scatter(actual, predictions)\n",
        "    plt.xlabel('Ist Menge')\n",
        "    plt.ylabel('Forecast Menge')\n",
        "    plt.plot([minValue,maxValue], [minValue,maxValue])\n",
        "    plt.xlim(minValue, maxValue)\n",
        "    plt.ylim(minValue, maxValue)\n",
        "\n",
        "    # Arrangieren der Ausgabe\n",
        "    plt.gca().set_aspect('equal', adjustable='box')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "sFGGVAicd7H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PoV des Modells / Betrachtungsrahmen\n",
        "graphPredictions(model, x, y, 0, 50)"
      ],
      "metadata": {
        "id": "taOq_HiseOaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neuen Input definieren\n",
        "new_inputs = {\n",
        "    'Temperatur': [AAAAA],\n",
        "    'Sondereffekt': [0, 0, 0, 0, 0],\n",
        "    'Sonnenschein': [1, 1, 1, 1, 0],\n",
        "    'Wochenende': [0, 0, 1, 1, 0],\n",
        "    'Sonderoeffnungszeit': [0, 1, 1, 1, 0]\n",
        "}\n",
        "\n",
        "# DataFrame aus neuen Inputs erstellen\n",
        "new_df = pd.DataFrame(new_inputs)\n",
        "\n",
        "# Standardisieren der Temperatur in den neuen Daten\n",
        "new_df[AAAAA] = (new_df[AAAAA] - [AAAAAA]) / [AAAAA]\n",
        "\n",
        "# Umwandeln der neuen Daten in einen Tensor\n",
        "new_x = torch.tensor(new_df.values, dtype=torch.float, device=device)\n",
        "\n",
        "# Vorhersagen für die neuen Daten machen\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    new_predictions = model(new_x)\n",
        "\n",
        "# Rück-Standardisieren der Vorhersagen\n",
        "new_predictions = new_predictions * numMengeStd + numMengeMean\n",
        "\n",
        "# Ausgabe der vorhergesagten Werte\n",
        "print(\"Vorhergesagte Mengen:\", new_predictions.cpu().numpy())\n",
        "\n"
      ],
      "metadata": {
        "id": "GJOOLsUjz8ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zUCeIQeV11bj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}